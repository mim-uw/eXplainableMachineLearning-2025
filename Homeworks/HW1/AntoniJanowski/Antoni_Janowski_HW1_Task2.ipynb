{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the 'adult' dataset, because it is big and because in the linked git hub page, there is a tutorial which nicely describes what this dataset is and what its columns represent. It is data from 1994 US census and it contains various information about roughly 40k people. The predicted variable is weather a person earns more than $50k a year. The protected characteristic that I will be focusing on is race, because racial inequalities in the US are a prominent topic. I assume that white people are a privileged group and that non-white people are not. I start by preparing the data, one hot encoding categorical variables etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. I chose a logistic regression model because it is very easy to train and does not require a lot of code. It achived 85,38% acuracy and I got the following fairnes statistics: \n",
    "\n",
    "group fariness =  1.74;\n",
    "equal oportunity =  1.0658;\n",
    "predictive_equality =  1.9039;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. As a second model I chose an XG-boost model. It performed a little better than linear regression, scoring 87% accuracy. The fairness statistics were as follows:\n",
    "\n",
    "group fariness =  1.67;\n",
    "equal oportunity =  1.015;\n",
    "predictive_equality =  1.904"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. I noticed that the data was very racially unbalanced. In the training set, there were data about 20757 white people and 3372 non_white people (including people form at least 5 different ethnic backgrounds). I sampled a new dataset, containing all the data about non-white people and equal number of randomly sampled white people. I trained a new logistic regression model on this dataset. It scored 85,36% and achieved following fairness statistic's:\n",
    " \n",
    "group fariness =  1.7247;\n",
    "equal oportunity =  1.0523;\n",
    "predictive_equality =  1.9110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. All models performed vary similarly. It is hard to notice any correlations or trade-offs from this data. The XG-boost model is clearly the best, both jugged by accuracy and the fairness metrics. Data balancing seem to improve fairness metrics slightly, but its effect is not vary impactful."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

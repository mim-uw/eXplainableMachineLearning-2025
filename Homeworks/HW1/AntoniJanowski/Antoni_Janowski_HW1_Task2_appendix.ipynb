{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data, removing nan values, normalizing columns with huge variance, one hot encoding categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Final Weight</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education Number of Years</th>\n",
       "      <th>Marital-status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>Hours-per-week</th>\n",
       "      <th>Native-country</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age          Workclass  Final Weight   Education  \\\n",
       "0   39          State-gov         77516   Bachelors   \n",
       "1   50   Self-emp-not-inc         83311   Bachelors   \n",
       "2   38            Private        215646     HS-grad   \n",
       "\n",
       "   Education Number of Years       Marital-status          Occupation  \\\n",
       "0                         13        Never-married        Adm-clerical   \n",
       "1                         13   Married-civ-spouse     Exec-managerial   \n",
       "2                          9             Divorced   Handlers-cleaners   \n",
       "\n",
       "     Relationship    Race Gender  Capital-gain  Capital-loss  Hours-per-week  \\\n",
       "0   Not-in-family   White   Male          2174             0              40   \n",
       "1         Husband   White   Male             0             0              13   \n",
       "2   Not-in-family   White   Male             0             0              40   \n",
       "\n",
       "   Native-country  Income  \n",
       "0   United-States   <=50K  \n",
       "1   United-States   <=50K  \n",
       "2   United-States   <=50K  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"Age\", \"Workclass\", \"Final Weight\", \"Education\", \"Education Number of Years\", \"Marital-status\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\", \"Capital-gain\", \"Capital-loss\", \"Hours-per-week\", \"Native-country\", \"Income\"]\n",
    "df = pd.read_csv(\"C:/Users/Dell/Documents/Explainable_machine_learning_2024/datasets/datasets/adult/raw/adult.data\", index_col=None, header=None, names=columns)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workclass  unique values:  [' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'\n",
      " ' ?' ' Self-emp-inc' ' Without-pay' ' Never-worked']\n",
      "Education  unique values:  [' Bachelors' ' HS-grad' ' 11th' ' Masters' ' 9th' ' Some-college'\n",
      " ' Assoc-acdm' ' Assoc-voc' ' 7th-8th' ' Doctorate' ' Prof-school'\n",
      " ' 5th-6th' ' 10th' ' 1st-4th' ' Preschool' ' 12th']\n",
      "Marital-status  unique values:  [' Never-married' ' Married-civ-spouse' ' Divorced'\n",
      " ' Married-spouse-absent' ' Separated' ' Married-AF-spouse' ' Widowed']\n",
      "Occupation  unique values:  [' Adm-clerical' ' Exec-managerial' ' Handlers-cleaners' ' Prof-specialty'\n",
      " ' Other-service' ' Sales' ' Craft-repair' ' Transport-moving'\n",
      " ' Farming-fishing' ' Machine-op-inspct' ' Tech-support' ' ?'\n",
      " ' Protective-serv' ' Armed-Forces' ' Priv-house-serv']\n",
      "Relationship  unique values:  [' Not-in-family' ' Husband' ' Wife' ' Own-child' ' Unmarried'\n",
      " ' Other-relative']\n",
      "Race  unique values:  [' White' ' Black' ' Asian-Pac-Islander' ' Amer-Indian-Eskimo' ' Other']\n",
      "Gender  unique values:  [' Male' ' Female']\n",
      "Native-country  unique values:  [' United-States' ' Cuba' ' Jamaica' ' India' ' ?' ' Mexico' ' South'\n",
      " ' Puerto-Rico' ' Honduras' ' England' ' Canada' ' Germany' ' Iran'\n",
      " ' Philippines' ' Italy' ' Poland' ' Columbia' ' Cambodia' ' Thailand'\n",
      " ' Ecuador' ' Laos' ' Taiwan' ' Haiti' ' Portugal' ' Dominican-Republic'\n",
      " ' El-Salvador' ' France' ' Guatemala' ' China' ' Japan' ' Yugoslavia'\n",
      " ' Peru' ' Outlying-US(Guam-USVI-etc)' ' Scotland' ' Trinadad&Tobago'\n",
      " ' Greece' ' Nicaragua' ' Vietnam' ' Hong' ' Ireland' ' Hungary'\n",
      " ' Holand-Netherlands']\n",
      "Income  unique values:  [' <=50K' ' >50K']\n"
     ]
    }
   ],
   "source": [
    "qualitative_columns = ['Workclass', \"Education\", 'Marital-status', 'Occupation', \"Relationship\", 'Race', 'Gender', 'Native-country']\n",
    "for col in qualitative_columns + ['Income']:\n",
    "    print(col, ' unique values: ', df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.replace(' ?', np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Final Weight', 'Education Number of Years', 'Capital-gain',\n",
      "       'Capital-loss', 'Hours-per-week', 'Income', 'Workclass_ Local-gov',\n",
      "       'Workclass_ Private', 'Workclass_ Self-emp-inc',\n",
      "       'Workclass_ Self-emp-not-inc', 'Workclass_ State-gov',\n",
      "       'Workclass_ Without-pay', 'Education_ 11th', 'Education_ 12th',\n",
      "       'Education_ 1st-4th', 'Education_ 5th-6th', 'Education_ 7th-8th',\n",
      "       'Education_ 9th', 'Education_ Assoc-acdm', 'Education_ Assoc-voc',\n",
      "       'Education_ Bachelors', 'Education_ Doctorate', 'Education_ HS-grad',\n",
      "       'Education_ Masters', 'Education_ Preschool', 'Education_ Prof-school',\n",
      "       'Education_ Some-college', 'Marital-status_ Married-AF-spouse',\n",
      "       'Marital-status_ Married-civ-spouse',\n",
      "       'Marital-status_ Married-spouse-absent',\n",
      "       'Marital-status_ Never-married', 'Marital-status_ Separated',\n",
      "       'Marital-status_ Widowed', 'Occupation_ Armed-Forces',\n",
      "       'Occupation_ Craft-repair', 'Occupation_ Exec-managerial',\n",
      "       'Occupation_ Farming-fishing', 'Occupation_ Handlers-cleaners',\n",
      "       'Occupation_ Machine-op-inspct', 'Occupation_ Other-service',\n",
      "       'Occupation_ Priv-house-serv', 'Occupation_ Prof-specialty',\n",
      "       'Occupation_ Protective-serv', 'Occupation_ Sales',\n",
      "       'Occupation_ Tech-support', 'Occupation_ Transport-moving',\n",
      "       'Relationship_ Not-in-family', 'Relationship_ Other-relative',\n",
      "       'Relationship_ Own-child', 'Relationship_ Unmarried',\n",
      "       'Relationship_ Wife', 'Race_ Asian-Pac-Islander', 'Race_ Black',\n",
      "       'Race_ Other', 'Race_ White', 'Gender_ Male', 'Native-country_ Canada',\n",
      "       'Native-country_ China', 'Native-country_ Columbia',\n",
      "       'Native-country_ Cuba', 'Native-country_ Dominican-Republic',\n",
      "       'Native-country_ Ecuador', 'Native-country_ El-Salvador',\n",
      "       'Native-country_ England', 'Native-country_ France',\n",
      "       'Native-country_ Germany', 'Native-country_ Greece',\n",
      "       'Native-country_ Guatemala', 'Native-country_ Haiti',\n",
      "       'Native-country_ Holand-Netherlands', 'Native-country_ Honduras',\n",
      "       'Native-country_ Hong', 'Native-country_ Hungary',\n",
      "       'Native-country_ India', 'Native-country_ Iran',\n",
      "       'Native-country_ Ireland', 'Native-country_ Italy',\n",
      "       'Native-country_ Jamaica', 'Native-country_ Japan',\n",
      "       'Native-country_ Laos', 'Native-country_ Mexico',\n",
      "       'Native-country_ Nicaragua',\n",
      "       'Native-country_ Outlying-US(Guam-USVI-etc)', 'Native-country_ Peru',\n",
      "       'Native-country_ Philippines', 'Native-country_ Poland',\n",
      "       'Native-country_ Portugal', 'Native-country_ Puerto-Rico',\n",
      "       'Native-country_ Scotland', 'Native-country_ South',\n",
      "       'Native-country_ Taiwan', 'Native-country_ Thailand',\n",
      "       'Native-country_ Trinadad&Tobago', 'Native-country_ United-States',\n",
      "       'Native-country_ Vietnam', 'Native-country_ Yugoslavia'],\n",
      "      dtype='object')\n",
      "   Age  Final Weight  Education Number of Years  Capital-gain  Capital-loss  \\\n",
      "0   39       0.05221                         13       0.02174             0   \n",
      "\n",
      "   Hours-per-week  Income  Workclass_ Local-gov  Workclass_ Private  \\\n",
      "0              40       0                   0.0                 0.0   \n",
      "\n",
      "   Workclass_ Self-emp-inc  ...  Native-country_ Portugal  \\\n",
      "0                      0.0  ...                       0.0   \n",
      "\n",
      "   Native-country_ Puerto-Rico  Native-country_ Scotland  \\\n",
      "0                          0.0                       0.0   \n",
      "\n",
      "   Native-country_ South  Native-country_ Taiwan  Native-country_ Thailand  \\\n",
      "0                    0.0                     0.0                       0.0   \n",
      "\n",
      "   Native-country_ Trinadad&Tobago  Native-country_ United-States  \\\n",
      "0                              0.0                            1.0   \n",
      "\n",
      "   Native-country_ Vietnam  Native-country_ Yugoslavia  \n",
      "0                      0.0                         0.0  \n",
      "\n",
      "[1 rows x 97 columns]\n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df_cleaned, columns=qualitative_columns, drop_first=True, dtype = float)\n",
    "df_encoded = df_encoded.replace(' <=50K', 0)\n",
    "df_encoded = df_encoded.replace(' >50K', 1)\n",
    "print(df_encoded.columns)\n",
    "\n",
    "df_normalized = df_encoded.copy()\n",
    "df_normalized['Final Weight'] = df_encoded['Final Weight'] / df_encoded['Final Weight'].max()\n",
    "df_normalized['Capital-gain'] = df_encoded['Capital-gain'] / df_encoded['Capital-gain'].max()\n",
    "# df_normalized['Final Weight'] = df_encoded['Final Weight'] / df_encoded['Final Weight'].max()\n",
    "\n",
    "# Display the encoded DataFrame\n",
    "print(df_normalized.head(1))\n",
    "# count_sex = df['Gender'].value_counts()\n",
    "# print(count_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Age  Final Weight  Education Number of Years  Capital-gain  \\\n",
      "0       39      0.052210                         13      0.021740   \n",
      "1       50      0.056113                         13      0.000000   \n",
      "2       38      0.145245                          9      0.000000   \n",
      "3       53      0.158093                          7      0.000000   \n",
      "4       28      0.227930                         13      0.000000   \n",
      "...    ...           ...                        ...           ...   \n",
      "32556   27      0.173302                         12      0.000000   \n",
      "32557   40      0.103976                          9      0.000000   \n",
      "32558   58      0.102317                          9      0.000000   \n",
      "32559   22      0.135710                          9      0.000000   \n",
      "32560   52      0.193929                          9      0.150242   \n",
      "\n",
      "       Capital-loss  Hours-per-week  Income  Workclass_ Local-gov  \\\n",
      "0                 0              40       0                   0.0   \n",
      "1                 0              13       0                   0.0   \n",
      "2                 0              40       0                   0.0   \n",
      "3                 0              40       0                   0.0   \n",
      "4                 0              40       0                   0.0   \n",
      "...             ...             ...     ...                   ...   \n",
      "32556             0              38       0                   0.0   \n",
      "32557             0              40       1                   0.0   \n",
      "32558             0              40       0                   0.0   \n",
      "32559             0              20       0                   0.0   \n",
      "32560             0              40       1                   0.0   \n",
      "\n",
      "       Workclass_ Private  Workclass_ Self-emp-inc  ...  \\\n",
      "0                     0.0                      0.0  ...   \n",
      "1                     0.0                      0.0  ...   \n",
      "2                     1.0                      0.0  ...   \n",
      "3                     1.0                      0.0  ...   \n",
      "4                     1.0                      0.0  ...   \n",
      "...                   ...                      ...  ...   \n",
      "32556                 1.0                      0.0  ...   \n",
      "32557                 1.0                      0.0  ...   \n",
      "32558                 1.0                      0.0  ...   \n",
      "32559                 1.0                      0.0  ...   \n",
      "32560                 0.0                      1.0  ...   \n",
      "\n",
      "       Native-country_ Portugal  Native-country_ Puerto-Rico  \\\n",
      "0                           0.0                          0.0   \n",
      "1                           0.0                          0.0   \n",
      "2                           0.0                          0.0   \n",
      "3                           0.0                          0.0   \n",
      "4                           0.0                          0.0   \n",
      "...                         ...                          ...   \n",
      "32556                       0.0                          0.0   \n",
      "32557                       0.0                          0.0   \n",
      "32558                       0.0                          0.0   \n",
      "32559                       0.0                          0.0   \n",
      "32560                       0.0                          0.0   \n",
      "\n",
      "       Native-country_ Scotland  Native-country_ South  \\\n",
      "0                           0.0                    0.0   \n",
      "1                           0.0                    0.0   \n",
      "2                           0.0                    0.0   \n",
      "3                           0.0                    0.0   \n",
      "4                           0.0                    0.0   \n",
      "...                         ...                    ...   \n",
      "32556                       0.0                    0.0   \n",
      "32557                       0.0                    0.0   \n",
      "32558                       0.0                    0.0   \n",
      "32559                       0.0                    0.0   \n",
      "32560                       0.0                    0.0   \n",
      "\n",
      "       Native-country_ Taiwan  Native-country_ Thailand  \\\n",
      "0                         0.0                       0.0   \n",
      "1                         0.0                       0.0   \n",
      "2                         0.0                       0.0   \n",
      "3                         0.0                       0.0   \n",
      "4                         0.0                       0.0   \n",
      "...                       ...                       ...   \n",
      "32556                     0.0                       0.0   \n",
      "32557                     0.0                       0.0   \n",
      "32558                     0.0                       0.0   \n",
      "32559                     0.0                       0.0   \n",
      "32560                     0.0                       0.0   \n",
      "\n",
      "       Native-country_ Trinadad&Tobago  Native-country_ United-States  \\\n",
      "0                                  0.0                            1.0   \n",
      "1                                  0.0                            1.0   \n",
      "2                                  0.0                            1.0   \n",
      "3                                  0.0                            1.0   \n",
      "4                                  0.0                            0.0   \n",
      "...                                ...                            ...   \n",
      "32556                              0.0                            1.0   \n",
      "32557                              0.0                            1.0   \n",
      "32558                              0.0                            1.0   \n",
      "32559                              0.0                            1.0   \n",
      "32560                              0.0                            1.0   \n",
      "\n",
      "       Native-country_ Vietnam  Native-country_ Yugoslavia  \n",
      "0                          0.0                         0.0  \n",
      "1                          0.0                         0.0  \n",
      "2                          0.0                         0.0  \n",
      "3                          0.0                         0.0  \n",
      "4                          0.0                         0.0  \n",
      "...                        ...                         ...  \n",
      "32556                      0.0                         0.0  \n",
      "32557                      0.0                         0.0  \n",
      "32558                      0.0                         0.0  \n",
      "32559                      0.0                         0.0  \n",
      "32560                      0.0                         0.0  \n",
      "\n",
      "[30162 rows x 97 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Training the first model, simple logistic regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.8538\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'train' is your DataFrame\n",
    "X = df_normalized.drop(columns=['Income'])  # Features\n",
    "y = df_normalized['Income']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model with L1 penalty (Lasso)\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear')  # 'liblinear' supports L1\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model (optional)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We will look at race as a protected characteristic. We will assume that white people are privileged and other are not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_white shape: (5176, 96), y_test_white shape: (5176,)\n",
      "x_test_other shape: (857, 96), y_test_other shape: (857,)\n"
     ]
    }
   ],
   "source": [
    "# Creating 'white' DataFrames (rows where 'Race_White' == 1)\n",
    "x_test_white = X_test[X_test['Race_ White'] == 1]\n",
    "y_test_white = y_test[X_test['Race_ White'] == 1]\n",
    "\n",
    "# Creating 'other' DataFrames (rows where 'Race_White' != 1)\n",
    "x_test_other = X_test[X_test['Race_ White'] != 1]\n",
    "y_test_other = y_test[X_test['Race_ White'] != 1]\n",
    "\n",
    "# Optional: Print the sizes of the new DataFrames\n",
    "print(f\"x_test_white shape: {x_test_white.shape}, y_test_white shape: {y_test_white.shape}\")\n",
    "print(f\"x_test_other shape: {x_test_other.shape}, y_test_other shape: {y_test_other.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy in white class: 0.8458268933539412\n",
      "accuracy in other class: 0.9008168028004667\n"
     ]
    }
   ],
   "source": [
    "predicted_y_white = model.predict(x_test_white)\n",
    "predicted_y_other = model.predict(x_test_other)\n",
    "print('accuracy in white class:', model.score(x_test_white, y_test_white))\n",
    "print('accuracy in other class:', model.score(x_test_other, y_test_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group fariness =  1.740037709657107\n",
      "equal oportunity =  1.0658998322549722\n",
      "predictive_equality =  1.9039874749253876\n"
     ]
    }
   ],
   "source": [
    "def calculate_group_fairness(predicted_y_white, predicted_y_other):\n",
    "    p_white = np.sum(predicted_y_white) / predicted_y_white.shape[0]\n",
    "    p_other = np.sum(predicted_y_other) / predicted_y_other.shape[0]\n",
    "    return p_white/p_other\n",
    "\n",
    "def calculate_equal_oportunity(predicted_y_white, predicted_y_other, true_y_white, true_y_other):\n",
    "    earn_more_white = predicted_y_white[true_y_white == 1]\n",
    "    earn_more_other = predicted_y_other[true_y_other == 1]\n",
    "    p_white = np.sum(earn_more_white) / earn_more_white.shape[0]\n",
    "    p_other = np.sum(earn_more_other) / earn_more_other.shape[0]\n",
    "    return p_white/p_other\n",
    "\n",
    "def calculate_predictive_equality(predicted_y_white, predicted_y_other, true_y_white, true_y_other):\n",
    "    earn_more_white = predicted_y_white[true_y_white == 0]\n",
    "    earn_more_other = predicted_y_other[true_y_other == 0]\n",
    "    p_white = np.sum(earn_more_white) / earn_more_white.shape[0]\n",
    "    p_other = np.sum(earn_more_other) / earn_more_other.shape[0]\n",
    "    return p_white/p_other\n",
    "\n",
    "print('group fariness = ', calculate_group_fairness(predicted_y_white, predicted_y_other))\n",
    "print('equal oportunity = ', calculate_equal_oportunity(predicted_y_white, predicted_y_other, y_test_white, y_test_other))\n",
    "print('predictive_equality = ', calculate_predictive_equality(predicted_y_white, predicted_y_other, y_test_white, y_test_other))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We will train the second model, an xg boost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set hyperparameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'logloss',        # Evaluation metric: Log loss\n",
    "    'max_depth': 6,                  # Maximum depth of trees\n",
    "    'eta': 0.3,                      # Learning rate\n",
    "    'lambda': 1,                     # L2 regularization (Ridge)\n",
    "    'alpha': 0,                      # L1 regularization (Lasso)\n",
    "}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "y_pred_proba = bst.predict(dtest)  # Predicted probabilities\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)  # Convert to binary (0 or 1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "dtest_white = xgb.DMatrix(x_test_white, label=y_test_white)\n",
    "dtest_other = xgb.DMatrix(x_test_other, label=y_test_other)\n",
    "xgb_predicted_white = bst.predict(dtest_white)\n",
    "xgb_predicted_white = (xgb_predicted_white >= 0.5).astype(int)\n",
    "xgb_predicted_other = bst.predict(dtest_other)\n",
    "xgb_predicted_other = (xgb_predicted_other >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group fariness =  1.6777949510561567\n",
      "equal oportunity =  1.01522706762317\n",
      "predictive_equality =  1.9042576973884768\n"
     ]
    }
   ],
   "source": [
    "print('group fariness = ', calculate_group_fairness(xgb_predicted_white, xgb_predicted_other))\n",
    "print('equal oportunity = ', calculate_equal_oportunity(xgb_predicted_white, xgb_predicted_other, y_test_white, y_test_other))\n",
    "print('predictive_equality = ', calculate_predictive_equality(xgb_predicted_white, xgb_predicted_other, y_test_white, y_test_other))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We can see that the classes are weary unbalanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race_ White\n",
      "1.0    20757\n",
      "0.0     3372\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_white = X_train['Race_ White'].value_counts()\n",
    "print(count_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train a model on a more balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced X_train shape: (6744, 96)\n",
      "Balanced y_train shape: (6744,)\n"
     ]
    }
   ],
   "source": [
    "# Separate rows based on the 'Race_White' column in X_train\n",
    "X_white_0 = X_train[X_train['Race_ White'] == 0]  # All rows with 'Race_White' == 0\n",
    "X_white_1 = X_train[X_train['Race_ White'] == 1]  # All rows with 'Race_White' == 1\n",
    "\n",
    "# Randomly sample from 'Race_White' == 1 to match the count of 'Race_White' == 0\n",
    "X_white_1_sampled = X_white_1.sample(n=len(X_white_0), random_state=42)\n",
    "\n",
    "# Combine the two DataFrames to create a balanced DataFrame\n",
    "X_train_balanced = pd.concat([X_white_0, X_white_1_sampled], ignore_index=True)\n",
    "\n",
    "# Create y_train_balanced corresponding to the balanced X_train\n",
    "# Get indices of sampled rows for 'Race_White' == 1\n",
    "indices_1_sampled = X_white_1_sampled.index\n",
    "\n",
    "# Combine the corresponding y values for 'Race_White' == 0 and the sampled 'Race_White' == 1\n",
    "y_train_balanced = pd.concat([y_train[X_train['Race_ White'] == 0], y_train.loc[indices_1_sampled]], ignore_index=True)\n",
    "\n",
    "# Optional: Shuffle the rows for randomness\n",
    "X_train_balanced = X_train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train_balanced = y_train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print the shapes of the new DataFrames\n",
    "print(f\"Balanced X_train shape: {X_train_balanced.shape}\")\n",
    "print(f\"Balanced y_train shape: {y_train_balanced.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.8536\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression model with L1 penalty (Lasso)\n",
    "model_balanced = LogisticRegression(penalty='l1', solver='liblinear')  # 'liblinear' supports L1\n",
    "\n",
    "# Fit the model\n",
    "model_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate the model (optional)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_white_balanced = model_balanced.predict(x_test_white)\n",
    "predicted_y_other_balanced = model_balanced.predict(x_test_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group fariness =  1.7247069809376612\n",
      "equal oportunity =  1.052329348279504\n",
      "predictive_equality =  1.9110132589657027\n"
     ]
    }
   ],
   "source": [
    "print('group fariness = ', calculate_group_fairness(predicted_y_white_balanced, predicted_y_other_balanced))\n",
    "print('equal oportunity = ', calculate_equal_oportunity(predicted_y_white_balanced, predicted_y_other_balanced, y_test_white, y_test_other))\n",
    "print('predictive_equality = ', calculate_predictive_equality(predicted_y_white_balanced, predicted_y_other_balanced, y_test_white, y_test_other))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. All models bechave in very similar ways"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness analysis of the dataset Adult\n",
    "\n",
    "I've trained two models:\n",
    "\n",
    "|                        \t| Train score \t| Eval score \t    | \n",
    "|---------------------------|---------------|-------------------|\n",
    "| Gaussian Naive Bayes     \t| 0.79        \t| 0.79              |\n",
    "| Random Forest Classifier \t| 0.90          | 0.86              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and checked ther fairness for the protected attribute  =  gender\n",
    "\n",
    "| |Statistical Parity | TPR | FPR | PPV | NPV |\n",
    "|---------------------------|-------------------|-------|-------|-------|-------|\n",
    "| Gaussian Naive Bayes | <span style=\"color:red\">0.54</span> | <span style=\"color:green\">1.03</span> | <span style=\"color:green\">0.72</span> | <span style=\"color:red\">0.69</span> | <span style=\"color:green\">1.21</span> |\n",
    "| Random Forest Classifier | <span style=\"color:red\">0.31</span> | <span style=\"color:green\">0.90</span> | <span style=\"color:red\">0.20</span> | <span style=\"color:green\">1.03</span> | <span style=\"color:green\">1.10</span> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness conclusions\n",
    "    - The fairness of models is fairly similar.\n",
    "    - Models predict women to be less likely to achieve >=50k than men which we can deduce from Statistical Parity (on average men are are more likely to be predicted with higher income) and FPR (model is more likely to correctly predict a person to earn less if they are a woman).  \n",
    "    - The marked as red coefficients don't follow the four-fifth rule, others do.\n",
    "    - Model with higher accuracy is less fair.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Mitigation\n",
    "I've implemented upsampling of women with high earnings, because they are underrepresented in the dataset.\n",
    "However it didn't affect the first model too much so I'll skip the results of it, and I'll focus on results from aplying upsampling to the Random Forest Classifier.\n",
    "\n",
    "|                        \t| Train score \t| Eval score \t    |\n",
    "|---------------------------|---------------|-------------------|\n",
    "| **Random Forest Upsampled** \t| 0.90          | 0.85              | \n",
    "| Gaussian Naive Bayes     \t| 0.79        \t| 0.79              |\n",
    "| Random Forest Classifier \t| 0.90          | 0.86              |\n",
    "\n",
    "Fairness Coefficients:\n",
    "\n",
    "| |Statistical Parity | TPR | FPR | PPV | NPV |\n",
    "|---------------------------|-------------------|-------|-------|-------|-------|\n",
    "| **Random Forest Upsampled** | <span style=\"color:red\">0.64</span> | <span style=\"color:red\">1.32</span> | <span style=\"color:green\">1.21</span> | <span style=\"color:red\">0.74</span> | <span style=\"color:green\">1.13</span> |\n",
    "| Gaussian Naive Bayes | <span style=\"color:red\">0.54</span> | <span style=\"color:green\">1.03</span> | <span style=\"color:green\">0.72</span> | <span style=\"color:red\">0.69</span> | <span style=\"color:green\">1.21</span> |\n",
    "| Random Forest Classifier | <span style=\"color:red\">0.31</span> | <span style=\"color:green\">0.90</span> | <span style=\"color:red\">0.20</span> | <span style=\"color:green\">1.03</span> | <span style=\"color:green\">1.10</span> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of results \n",
    "The accuracy decreased but not substantially. However, it's harder to decide if the fairness incresed since some coefficients got better and other got worse. It seems that on average it got a bit more fair.\n",
    "\n",
    "Clearly the least fair is the Random Forest Classifier which has the highest accuracy and then Gaussian Naive Bayes and Random Forest Classifier Upsampled seem to have more or less similar fairness. \n",
    "\n",
    "In the context of statistical parity it makes sense because the groundtruth has statistical parity of 0.36 so the closer the model gets to the ground truth the closer its statistical parity  gets to 0.36 (which doesn't follow fairness rules)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
